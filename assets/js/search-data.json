{
  
    
        "post0": {
            "title": "Key Driver Analysis",
            "content": "What is Key Driver Analysis? . Key Driver Analysis‚ÄØis also known as‚ÄØImportance Analysis and‚ÄØRelative Importance Analysis. The goal of this analysis is to quantify the‚ÄØrelative importance‚ÄØof each of the predictor variables in predicting the target variable. Each of the predictors is commonly referred to as a driver. . Generally, the output of Key Driver Analysis is a table or chart showing the‚ÄØRelative Importance‚ÄØof the drivers (predictors). . How is it different from traditional predictive models? . In classic predictive models, the focus is on prediction, whereas with key driver analysis the main focus is on identifying the relative importance of the predictors (drivers). . What are the supported target types to perform Key Driver Analysis? . Key driver analysis can be performed on almost all types of target types that are binary, categorical, and numerical. . How to perform Key Driver Analysis? . Key driver analysis can be performed with any of the following techniques. . Correlations - appropriate when we&#39;re not concerned about multi-collinearity. | Jaccard coefficient/index - This is similar to correlation, except it is only appropriate when both the predictor and outcome variables are binary. | Generalized Linear Models (GLM) To conduct a valid key driver analysis we need to select an appropriate generalized linear model (GLM) which is consistent with our data. Linear Regression - for continues target variable | Logistic Regression - for a binary target variable | Quasi Poisson Regression - for a decimal target variable | Ordered Logistic Regression - for a rating or ordered numerical target variable | . | . | Shapely Regression - This a regularized regression, designed for situations where linear regression results are unreliable due to high correlations between predictors. | Johnson Relative Weights - Similar to Shapley Regression, this is a regularized regression and it can be used for all types of target variables | Using Generalized Linear Models (GLMs) . In general when we build GLM&#39;s it&#39;s often observed that the coefficients are negative, however, in the case of key driver analysis this is an indication of a problem. The causes could be: . The sign is wrong The predictor variable is highly correlated with other predictors | The predictor is unimportant | . | The predictor variable encoded incorrectly | Downsides of using GLM&#39;s for Key Driver Analysis: . GLMs become highly unreliable when the predictors are highly correlated (multi-collinearity) and tend to pick up random patterns in the data, hence the possibility of incorrect signs. | GLMs implicitly assume that predictors are on the same scale. So, it become hard to compare the coefficients directly. The most popular way to solve this problem is to divide the each value of predictor by it&#39;s standard deviation (i.e., to normalize or standardize the variables) but it does not necessarily solve the problem. | The solution to the above 2 problems is to not use GLMs üòä, and to instead use models that are more reliable when there are high correlations and can handle feature that are on different scales, such as Shapley regression and Johnson‚Äôs relative weights. These techniques do not solve the problem of correlated predictors. Rather, they ensure that you get stable results in the presence of correlated predictors. At a conceptual level, the way they do this is by computing importance scores as a weighted average of predictors, where the weights are determined by the extent of intercorrelation between the predictors. . Using Shapley regression or Johnson&#8217;s relative weights . As it&#39;s mentioned earlier, the traditional GLMs suffer from two practical challenges: sensitivity to high correlations between predictor variables, and, sensitivity to the scale of the predictor variables. Both problems can be addressed by using either Shapley regression or Johnson‚Äôs relative weights. . The underlying math of both Shapley regression and Johnson‚Äôs relative weight ensures that both techniques always report a positive importance score. . Finally, which method is recommended to perform Key Driver Analysis? . Both Shapley regression and Johnson‚Äôs relative weights are designed to address the same two problems: correlations between predictor variables and predictor variables with different scales. . The underlying theory of the two methods are completely different. . Shapley regression is based on running lots of linear regressions with different subsets of predictor variables. | Johnson‚Äôs relative weights is an orthonormal rotation of the predictor variables. | . Nevertheless, the two methods give essentially identical results, so there is no need to understand the intricacies of the two methods in order to choose one. There are, however, two practical difference between the methods: . Shapley Regression is only applicable for linear regression. | Johnson‚Äôs Relative Weights is applicable for any GLM. | Johnson‚Äôs Relative Weights is much faster to compute than Shapley Regression. | . For these reasons, our preference is to always use Johnson‚Äôs Relative Weights üí™ for Key Driver Analysis . . Important: Though the theoretical assumptions of Johnson‚Äôs relative weights and Shapley regression assumes a positive importance score. Sometimes we may see negative coefficients, which is a clear indication that key driver analysis is incorrect. . References . https://www.displayr.com/what-is-driver-analysis/ | https://www.displayr.com/the-problem-with-using-multiple-linear-regression-for-key-driver-analysis-a-case-study-of-the-cola-market/ | https://www.displayr.com/shapley-value-regression | https://www.statisticshowto.com/relative-weights/ | https://www.displayr.com/reasons-to-use-relative-weights/ | https://measuringu.com/key-drivers/ | .",
            "url": "https://bnriiitb.github.io/blog/key-driver-analysis/driver-analysis/importance-analysis/relative-importance-analysis/johnson-relative-weights/shapley-regression/2021/05/04/key-driver-analysis.html",
            "relUrl": "/key-driver-analysis/driver-analysis/importance-analysis/relative-importance-analysis/johnson-relative-weights/shapley-regression/2021/05/04/key-driver-analysis.html",
            "date": " ‚Ä¢ May 4, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Weight of Evidence and Information Value (IV)",
            "content": "What is Weight of Evidence (WOE)? . The weight of evidence tells the predictive power of an independent variable in relation to the dependent variable. Since it evolved from credit scoring world, it is generally described as a measure of the separation of good and bad customers. &quot;Bad Customers&quot; refers to the customers who defaulted on a loan. and &quot;Good Customers&quot; refers to the customers who paid back loan. . These two concepts are simple, yet powerful techniques to perform variable transformation and selection. What is more, in contrast to more sophisticated models, they provide high interpretability. . The weight of evidence (WOE) and information value (IV) provide a great framework for for exploratory analysis and variable screening for binary classifiers. WOE and IV have been used extensively in the credit risk world for several decades, and the underlying theory dates back to the 1950s. However, it is still not widely used outside the credit risk world . Note: Positive WOE means Distribution of Goods $&gt;$ Distribution of Bads. Negative WOE means Distribution of Goods $&lt;$ Distribution of Bads. Hint : Log of a number $&gt;$ 1 means positive value. If less than 1, it means negative value. . A brief history of WOE . Weight Of Evidence (WOE) and Information Value (IV) evolved from the logistic regression technique. These two terms have been in existence in credit scoring world for more than 4-5 decades They have been used as a benchmark to screen variables in the credit risk modeling projects such as probability of default. They help to explore data and screen variables. It is also used in marketing analytics project such as customer attrition model, campaign response model etc. . It&#39;s good to understand the concept of WOE in terms of events and non-events. It is calculated by taking the natural logarithm (log to base e) of division of % of non-events and % of events. . $ text{Wight of Evidence } = ln( frac{ % text{ of Non Events}}{ % text{ Events}})$ . Steps for Calculating WOE . Step 1: For a continuous variable, split data into 10 parts (or lesser depending on the distribution). | For a categorical variable, you do not need to split the data (Ignore Step 1 and follow the remaining steps) | . | Step 2: Calculate the number of events and non-events in each group (bin) | Step 3: Calculate the % of events and % of non-events in each group. | Step 4: Calculate WOE by taking natural log of division of % of non-events and % of events | . Terminology: . Fine Classing: Create 10/20 bins/groups for a continuous independent variable and then calculates WOE and IV of the variable. | Coarse Classing: Combine adjacent categories with similar WOE scores. | . Usage of WOE . Weight of Evidence (WOE) helps to transform a continuous independent variable into a set of groups or bins based on similarity of dependent variable distribution i.e. number of events and non-events. . For continuous independent variables : First, create bins (categories / groups) for a continuous independent variable and then combine categories with similar WOE values and replace categories with WOE values. Use WOE values rather than input values in your model. . For categorical independent variables : Combine categories with similar WOE and then create new categories of an independent variable with continuous WOE values. In other words, use WOE values rather than raw categories in your model. The transformed variable will be a continuous variable with WOE values. It is same as any continuous variable. . Why combine categories with similar WOE? . It is because the categories with similar WOE have almost same proportion of events and non-events. In other words, the behavior of both the categories is same. Rules related to WOE Each category (bin) should have at least 5% of the observations. Each category (bin) should be non-zero for both non-events and events. The WOE should be distinct for each category. Similar groups should be aggregated. The WOE should be monotonic, i.e. either growing or decreasing with the groupings. Missing values are binned separately. . Number of Bins (Groups) . In general, 10 or 20 bins are taken. Ideally, each bin should contain at least 5% cases. The number of bins determines the amount of smoothing - the fewer bins, the more smoothing. If someone asks you &#39; &quot;why not to form 1000 bins?&quot; The answer is the fewer bins capture important patterns in the data, while leaving out noise. Bins with less than 5% cases might not be a true picture of the data distribution and might lead to model instability. . Handle Zero Event/ Non-Event . If a particular bin contains no event or non-event, you can use the formula below to ignore missing WOE. We are adding 0.5 to the number of events and non-events in a group. . AdjustedWOE = ln (((Number of non-events in a group + 0.5) / Number of non-events)) / ((Number of events in a group + 0.5) / Number of events)) . References: . https://www.cs.tufts.edu/~nr/cs257/archive/jack-good/weight-of-evidence.pdf | https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html | https://multithreaded.stitchfix.com/blog/2015/08/13/weight-of-evidence/ | https://docs.tibco.com/data-science/GUID-44739B00-E85F-4CE7-8404-24F9B775ADE8.html | https://contrib.scikit-learn.org/category_encoders/woe.html | . About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://bnriiitb.github.io/blog/jupyter/2021/03/19/WOE.html",
            "relUrl": "/jupyter/2021/03/19/WOE.html",
            "date": " ‚Ä¢ Mar 19, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "How to choose a right Regression Analysis?",
            "content": "What is Regression Analysis? . Regression analysis models the relationships between a response variable and one or more predictor variables. You can use a regression model to understand how changes in the predictor values are associated with changes in the response mean. You can also use regression to make predictions based on the values of the predictors. . There are a variety of regression methodologies, the choice often depends on the kind of data you have for the dependent variable and the type of model that provides the best fit. . In this post, I&#39;ll cover the more common types of regression models and how to decide which one is appropriate for your data based on the dependent variable type (continuous, categorical, and count data) . Continuous Dependent Variable . Linear regression . Linear regression, also known as ordinary least squares (OLS) and linear least squares, is the real workhorse of the regression world. You can use linear regression to understand the mean change in a dependent variable given a one-unit change in each independent variable. You can also use polynomials to model curvature and include interaction effects. Despite the term linear model this type can model curvature. . OLS produces the fitted line that minimizes the sum of the squared differences between the data points and the line. . This analysis estimates parameters by minimizing the sum of the squared errors (SSE). Linear models are the most common and most straightforward to use. If you have a continuous dependent variable, linear regression is probably the first type you should consider. . Types of Linear Regression . Linear models are the oldest type of regression. It was designed so that statisticians can do the calculations by hand. However, OLS has several weaknesses, including a sensitivity to both outliers and multicollinearity, and it is prone to overfitting. To address these problems, statisticians have developed several advanced variants. . I. Ridge Regression . It allows you to analyze data even when severe multicollinearity is present and helps prevent overfitting. | This type of model reduces the large, problematic variance that multicollinearity causes by introducing a slight bias in the estimates. The procedure trades away much of the variance in exchange for a little bias, which produces more useful coefficient estimates when multicollinearity is present. | . II. Lasso Regression (Least Absolute Shrinkage and Selection Operator) . It performs variable selection that aims to increase prediction accuracy by identifying a simpler model. | It is similar to Ridge regression but with variable selection. | . III. Partial Least Squares (PLS) Regression . It is useful when you have a very few observations compared to the number of independent variables or when your independent variables are highly correlated. | PLS decreases the independent variables down to a smaller number of uncorrelated components, similar to Principal Components Analysis. Then, the procedure performs linear regression on these components rather the original data. | PLS emphasizes developing predictive models and is not used for screening variables. | Unlike OLS, you can include multiple continuous dependent variables. | PLS uses the correlation structure to identify smaller effects and model multivariate patterns in the dependent variables. | . References: . https://statisticsbyjim.com/regression/choosing-regression-analysis/ | . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://bnriiitb.github.io/blog/jupyter/2020/03/10/how_to_choose_regression_models.html",
            "relUrl": "/jupyter/2020/03/10/how_to_choose_regression_models.html",
            "date": " ‚Ä¢ Mar 10, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi there üëã . üî≠ I‚Äôm Naga, currently working as a Lead Data Scientist at TVS Motor Company | üå± I‚Äôm on a mission to generate value by leveraging AI! | üí¨ Ask me about machine learning, deep learning, reinforcement learning and systems for learning from data at scale. | üì´ Reach out to me on LinkedIn http://linkedin.com/in/nagarajubudigam/ | .",
          "url": "https://bnriiitb.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://bnriiitb.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}